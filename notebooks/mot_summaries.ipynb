{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Object Tracking  Datasets\n",
    "\n",
    "All dataset will have classes that read annotations. The dataset class needs to extend our custom `BaseDatasetTracking` class. \n",
    "\n",
    "The `BaseDatasetTracking` class has the following methods:\n",
    "\n",
    "* `generate_dataset_statistics`: generates a summary of the dataset (e.g. number of videos, number of annotations, etc.)\n",
    "* `save_dataset_statistics`: saves the summary to a `json` file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expose parent directory to import modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "while os.path.basename(ROOT_DIR) != 'DatasetsStatistics':\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(ROOT_DIR,'..'))\n",
    "sys.path.insert(0,ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK='MOT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. MOT 2017 dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 1. MOT 2017 dataset\n",
    "from bases.mot_coco import MOT_IN_COCO\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = 2017\n",
    "dataset_stem = f\"MOT{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_cocoformat\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = MOT_IN_COCO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# # generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. MOT 2020 dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 2. MOT 2020 dataset\n",
    "from bases.mot_coco import MOT_IN_COCO\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = 2020\n",
    "dataset_stem = f\"MOT{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_cocoformat\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = MOT_IN_COCO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# # generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.  Visdrone MOT dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 3. Visdrone MOT dataset\n",
    "from bases.visdrone_mot import VisDroneMOT \n",
    "from pathlib import Path\n",
    "\n",
    "tag = \"mot\"\n",
    "dataset_stem = f\"visdrone_{tag}\"\n",
    "split = \"visdrone_mot\"\n",
    "subset = f\"{split}_cocoformat\" \n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/converted_annotations/{subset}.json\")\n",
    "D = VisDroneMOT(annotation_file=str(annotiation_file))\n",
    "\n",
    "# # generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.  SKYDATA MOT dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 4.  SKYDATA MOT dataset\n",
    "\n",
    "# ##\n",
    "TASK='MOT'\n",
    "\n",
    "## 4. SKYDATA MOT dataset\n",
    "from bases.skydata_vis_dataset import SkyDataVis\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = \"\"\n",
    "dataset_stem = f\"skydata{dataset_year}\"\n",
    "split = \"train\"\n",
    "# subset = \"train_SKYVIS_ds5_fr3_alldata\"\n",
    "# \"data/skydata/annotations/train_SKYVIS_3_alldata.json\"\n",
    "subset = f\"{split}_SKYVIS_3_alldata\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = SkyDataVis(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. DanceTRack dataset**\n",
    "\n",
    "``` python\n",
    "## **5. DanceTRack dataset**\n",
    "\n",
    "# ##\n",
    "TASK='MOT'\n",
    "\n",
    "##**5. DanceTRack dataset**\n",
    "from bases.dancetrack_coco import DanceTrack\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = \"\"\n",
    "dataset_stem = f\"DanceTrack{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_cocoformat\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = DanceTrack(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. TAO dataset**\n",
    "\n",
    "``` python\n",
    "## **6. TAO dataset**\n",
    "\n",
    "# ##\n",
    "TASK='MOT'\n",
    "\n",
    "##**5. TAO dataset**\n",
    "from bases.dancetrack_coco import DanceTrack\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = \"\"\n",
    "dataset_stem = f\"tao{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_with_freeform\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = DanceTrack(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "indexing videos...\n",
      "updating annotations with video_id...\n",
      "indexing annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59200/59200 [00:00<00:00, 1218341.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames indexing...\n",
      "indexing categories...\n",
      "indexing categories to videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59200/59200 [00:00<00:00, 2087823.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing images to annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n",
      "100%|██████████| 2833/2833 [00:00<00:00, 73273.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "[INFO] Generating dataset statistics for the TAO...\n",
      "[INFO] saving ...: train_with_freeform_stats.json\n",
      "[INFO] dataset statistics saved to: summaries/MOT/tao/train_with_freeform_stats.json\n",
      "[INFO] Saved\n"
     ]
    }
   ],
   "source": [
    "## **6. TAO dataset**\n",
    "\n",
    "# ##\n",
    "TASK='MOT'\n",
    "\n",
    "##**5. TAO dataset**\n",
    "from bases.tao_mot_coco import TAO\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = \"\"\n",
    "dataset_stem = f\"tao{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_with_freeform\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = TAO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsetStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
