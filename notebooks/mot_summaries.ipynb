{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Object Tracking  Datasets\n",
    "\n",
    "All dataset will have classes that read annotations. The dataset class needs to extend our custom `BaseDatasetTracking` class. \n",
    "\n",
    "The `BaseDatasetTracking` class has the following methods:\n",
    "\n",
    "* `generate_dataset_statistics`: generates a summary of the dataset (e.g. number of videos, number of annotations, etc.)\n",
    "* `save_dataset_statistics`: saves the summary to a `json` file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expose parent directory to import modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "while os.path.basename(ROOT_DIR) != 'DatasetsStatistics':\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(ROOT_DIR,'..'))\n",
    "sys.path.insert(0,ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK='MOT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. MOT 2017 dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 1. MOT 2017 dataset\n",
    "from bases.mot_coco import MOT_IN_COCO\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = 2017\n",
    "dataset_stem = f\"MOT{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_cocoformat\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = MOT_IN_COCO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# # generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. MOT 2020 dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 2. MOT 2020 dataset\n",
    "from bases.mot_coco import MOT_IN_COCO\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = 2020\n",
    "dataset_stem = f\"MOT{dataset_year}\"\n",
    "split = \"train\"\n",
    "subset = f\"{split}_cocoformat\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = MOT_IN_COCO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# # generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.  Visdrone MOT dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 3. Visdrone MOT dataset\n",
    "from bases.visdrone_mot import VisDroneMOT \n",
    "from pathlib import Path\n",
    "\n",
    "tag = \"mot\"\n",
    "dataset_stem = f\"visdrone_{tag}\"\n",
    "split = \"visdrone_mot\"\n",
    "subset = f\"{split}_cocoformat\" \n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/converted_annotations/{subset}.json\")\n",
    "D = VisDroneMOT(annotation_file=str(annotiation_file))\n",
    "\n",
    "# # generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.  SKYDATA MOT dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## 4.  SKYDATA MOT dataset\n",
    "\n",
    "# ##\n",
    "TASK='MOT'\n",
    "\n",
    "## 4. SKYDATA MOT dataset\n",
    "from bases.skydata_vis_dataset import SkyDataVis\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = \"\"\n",
    "dataset_stem = f\"skydata{dataset_year}\"\n",
    "split = \"train\"\n",
    "# subset = \"train_SKYVIS_ds5_fr3_alldata\"\n",
    "# \"data/skydata/annotations/train_SKYVIS_3_alldata.json\"\n",
    "subset = f\"{split}_SKYVIS_3_alldata\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/annotations/{subset}.json\")\n",
    "D = SkyDataVis(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. DanceTRack dataset**\n",
    "\n",
    "``` python\n",
    "\n",
    "## **5. KAIST dataset**\n",
    "\n",
    "# ##\n",
    "TASK='MOT'\n",
    "\n",
    "##**5. KAIST dataset**\n",
    "from bases.kaist_mot import KaistMOT\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_year = \"\"\n",
    "dataset_stem = f\"kaist_pedestrian{dataset_year}\"\n",
    "split = \"kaist\"\n",
    "subset = f\"{split}_vid_cocoformat\"\n",
    "annotiation_file = Path(f\"./data/{dataset_stem}/converted_annotations/{subset}.json\")\n",
    "D = KaistMOT(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = f\"./summaries/{TASK}\",\n",
    "                            dataset_name = f\"{dataset_stem}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "print(f\"[INFO] Saved\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading annotations into memory...\n",
      "Done (t=0.55s)\n",
      "creating index...\n",
      "indexing videos...\n",
      "updating annotations with video_id...\n",
      "indexing annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/108132 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'instance_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/nalain/nalain-labs/ozerlabs/DatasetsStatistics/notebooks/mot_summaries.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nalain/nalain-labs/ozerlabs/DatasetsStatistics/notebooks/mot_summaries.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m subset \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m_vid_cocoformat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nalain/nalain-labs/ozerlabs/DatasetsStatistics/notebooks/mot_summaries.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m annotiation_file \u001b[39m=\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m{\u001b[39;00mdataset_stem\u001b[39m}\u001b[39;00m\u001b[39m/converted_annotations/\u001b[39m\u001b[39m{\u001b[39;00msubset\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nalain/nalain-labs/ozerlabs/DatasetsStatistics/notebooks/mot_summaries.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m D \u001b[39m=\u001b[39m KaistMOT(annotation_file\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(annotiation_file))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nalain/nalain-labs/ozerlabs/DatasetsStatistics/notebooks/mot_summaries.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# generate and load stats\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nalain/nalain-labs/ozerlabs/DatasetsStatistics/notebooks/mot_summaries.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m D\u001b[39m.\u001b[39mgenerate_dataset_statistics()\n",
      "File \u001b[0;32m~/nalain-labs/ozerlabs/DatasetsStatistics/bases/kaist_mot.py:51\u001b[0m, in \u001b[0;36mKaistMOT.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDone (t=\u001b[39m\u001b[39m{:0.2f}\u001b[39;00m\u001b[39ms)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39m tic))\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreateIndex()\n",
      "File \u001b[0;32m~/nalain-labs/ozerlabs/DatasetsStatistics/bases/kaist_mot.py:111\u001b[0m, in \u001b[0;36mKaistMOT.createIndex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mfor\u001b[39;00m ann \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    110\u001b[0m     anns[ann[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m ann\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mif\u001b[39;00m(ann[\u001b[39m\"\u001b[39;49m\u001b[39minstance_id\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(adjustedAnns\u001b[39m.\u001b[39mkeys())):\n\u001b[1;32m    112\u001b[0m         adjustedAnns[ann[\u001b[39m\"\u001b[39m\u001b[39minstance_id\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m {\n\u001b[1;32m    113\u001b[0m                                             \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: ann[\u001b[39m\"\u001b[39m\u001b[39minstance_id\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    114\u001b[0m                                             \u001b[39m\"\u001b[39m\u001b[39mvideo_id\u001b[39m\u001b[39m\"\u001b[39m: ann[\u001b[39m\"\u001b[39m\u001b[39mvideo_id\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                             \u001b[39m\"\u001b[39m\u001b[39miscrowd\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m\n\u001b[1;32m    120\u001b[0m                                             }\n\u001b[1;32m    122\u001b[0m     adjustedAnns[ann[\u001b[39m\"\u001b[39m\u001b[39minstance_id\u001b[39m\u001b[39m\"\u001b[39m]][\u001b[39m\"\u001b[39m\u001b[39mareas\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(ann[\u001b[39m\"\u001b[39m\u001b[39marea\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'instance_id'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsetStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
