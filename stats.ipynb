{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stats\n",
    "\n",
    "To generate stats, we will read the summary files for different datasets in `summary folder`. The summary folder contains folders named after the dataset name. Each dataset folder contains summary files extacted by respective scripts. The summary files are in json format. We will read the json files and generate stats.\n",
    "\n",
    "We will generate per dataset stats and general stats combining all the datasets.\n",
    "\n",
    "Among the stats, we will generate the following:\n",
    "\n",
    "* [ ] 1. Number of images `all_ds`\n",
    "* [ ] 2. Number of objects `all_ds`\n",
    "* [ ] 3. Number of classes `all_ds`\n",
    "* [ ] 4. Number of instances per class `per_ds` \n",
    "* [ ] 5. Average number of instances per image `all_ds` \n",
    "<!-- * [ ] 6. Bounding box area distribution `all_ds` -->\n",
    "\n",
    "\n",
    "The results will be saved in summaries in respective dataset folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nalain/miniconda3/envs/dsetStats/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "sns.set()\n",
    "\n",
    "from utils import stats_tools\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up paths\n",
    "current_dir = Path(os.getcwd())\n",
    "summaries_path = current_dir / 'summaries'\n",
    "summaries_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset to file paths\n",
    "dataset_to_file_paths = stats_tools.get_dataset_to_file_paths(str(summaries_path))\n",
    "\n",
    "# len(dataset_to_file_paths), dataset_to_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************visdrone********************\n",
      "[INFO] Loading visdrone_converted_to_coco_format_stats.json\n",
      "[INFO] Loaded visdrone_converted_to_coco_format_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************dota********************\n",
      "[INFO] Loading dotav2_converted_to_coco_stats.json\n",
      "[INFO] Loaded dotav2_converted_to_coco_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************kaist_pedestrian********************\n",
      "[INFO] Loading kaist_converted_to_coco_format_stats.json\n",
      "[INFO] Loaded kaist_converted_to_coco_format_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************skydata********************\n",
      "[INFO] Loading train_DET_stats.json\n",
      "[INFO] Loaded train_DET_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************vhr_10********************\n",
      "[INFO] Loading vhr_annotations_stats.json\n",
      "[INFO] Loaded vhr_annotations_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************vedai********************\n",
      "[INFO] Loading vedai_converted_to_coco_format_stats.json\n",
      "[INFO] Loaded vedai_converted_to_coco_format_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************coco2017********************\n",
      "[INFO] Loading instances_train2017_stats.json\n",
      "[INFO] Loaded instances_train2017_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************coco2014********************\n",
      "[INFO] Loading instances_train2014_stats.json\n",
      "[INFO] Loaded instances_train2014_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "********************kaist_roboflow********************\n",
      "[INFO] Loading kaist_train_annotations_coco_stats.json\n",
      "[INFO] Loaded kaist_train_annotations_coco_stats.json\n",
      "[INFO] Category stats ....\n",
      "[INFO] saving plot ....\n",
      "[INFO] Saved.\n",
      "[INFO] Saving summaries\n",
      "[INFO] Saved global_summary_plain_value_cols.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_summary_plain_value_cols_df = pd.DataFrame()\n",
    "\n",
    "for dataset_name, file_path in dataset_to_file_paths.items():\n",
    "    \n",
    "    print(\"*\"*20 + f\"{dataset_name}\" + \"*\"*20)\n",
    "    # load data\n",
    "    summary = stats_tools.load_summary(file_path=file_path)\n",
    "    dataset_to_summary = {dataset_name: summary}\n",
    "\n",
    "    # columns\n",
    "    all_columns = list(summary.keys())\n",
    "    # get columns that contain plain values (not lists or dicts)\n",
    "    plain_value_cols = { k:v for (k,v) in summary.items() if not isinstance(summary[k], (list, dict))}\n",
    "    plain_value_cols[\"dataset_name\"] = dataset_name\n",
    "\n",
    "    plain_value_cols_df=pd.DataFrame(plain_value_cols, index=[0])\n",
    "    # merge with already existing plain_value_cols_dfs\n",
    "    global_summary_plain_value_cols_df=stats_tools.merge_df(df1=global_summary_plain_value_cols_df, \n",
    "                                                            df2=plain_value_cols_df)\n",
    "    \n",
    "    #get _per_category_stats and plot them\n",
    "    # categories = summary['categories']\n",
    "    per_category_stats = summary['per_category_stats']\n",
    "    stats_tools.plot_and_save_per_category_stats(per_category_stats=per_category_stats, \n",
    "                                                    dataset_name=dataset_name, \n",
    "                                                    save_path=summaries_path)\n",
    "    \n",
    "    \n",
    "    # bbox_areas_stats = summary['bbox_areas_stats']\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# global_summary_plain_value_cols_df save to csv\n",
    "stats_tools.save_df_to_csv(df=global_summary_plain_value_cols_df,\n",
    "                            save_path=summaries_path,\n",
    "                            file_name='global_summary_plain_value_cols.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsetStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
