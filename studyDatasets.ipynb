{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "All dataset will have classes that read annotations. The dataset class needs to extend our custom `BaseDataset` class. \n",
    "\n",
    "The `BaseDataset` class has the following methods:\n",
    "\n",
    "* `generate_dataset_statistics`: generates a summary of the dataset (e.g. number of images, number of annotations, etc.)\n",
    "* `save_dataset_statistics`: saves the summary to a `json` file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Toy example**\n",
    "- get dataset instance\n",
    "- create index\n",
    "- generate statistics\n",
    "- save statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "# 0. Toy example\n",
    "\n",
    "from bases.example import Example\n",
    "\n",
    "D = Example()\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = None,\n",
    "                            file_name = None\n",
    "                            )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. COCO 2017 dataset**\n",
    "\n",
    "``` python\n",
    "## 1. COCO dataset\n",
    "\n",
    "from bases.coco import COCO\n",
    "from pathlib import Path\n",
    "\n",
    "coco_year = 2017\n",
    "subset = f\"instances_train{coco_year}\"\n",
    "annotiation_file = Path(f\"./data/coco/{coco_year}/annotations/{subset}.json\")\n",
    "D = COCO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"coco{coco_year}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. COCO 2014 dataset**\n",
    "\n",
    "``` python\n",
    "## 1. COCO dataset\n",
    "\n",
    "from bases.coco import COCO\n",
    "from pathlib import Path\n",
    "\n",
    "coco_year = 2014\n",
    "subset = f\"instances_train{coco_year}\"\n",
    "annotiation_file = Path(f\"./data/coco/{coco_year}/annotations/{subset}.json\")\n",
    "D = COCO(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"coco{coco_year}\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. SkyData dataset**\n",
    "\n",
    "\n",
    "```python\n",
    "## 2. Skydata \n",
    "\n",
    "from bases.skydata import SkyData\n",
    "from pathlib import Path\n",
    "\n",
    "subset = f\"train_DET\"\n",
    "annotiation_file = Path(f\"./data/skydata/annotations/{subset}.json\")\n",
    "D = SkyData(annotation_file=str(annotiation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"skydata\",\n",
    "                            file_name = f\"{subset}_stats.json\"\n",
    "                            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **3. Visdrone dataset**\n",
    "\n",
    "\n",
    "```python\n",
    "## 3. Visdrone \n",
    "\n",
    "from bases.visdrone import VisDrone\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/visdrone/converted_annotations\")\n",
    "annotation_file = converted_path / \"visdrone_converted_to_coco_format.json\"\n",
    "\n",
    "# if annotation_file does not exist, convert the dataset\n",
    "if not annotation_file.exists():\n",
    "\n",
    "    try:\n",
    "        #TODO this could be improved \n",
    "        # The script could take arguments \n",
    "        print(\"[INFO] Converting visdrone dataset to COCO format...\")\n",
    "        os.system(\"python ./scripts/convert_visdrone_to_coco_format.py\")\n",
    "        print(\"[INFO] Finished converting dataset to COCO format.\")\n",
    "    except:\n",
    "        print(\"[ERROR] Could not convert dataset to COCO format.\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "D = VisDrone(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"visdrone\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "                            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. KAIST ROBOFLOW dataset**\n",
    "\n",
    "```python\n",
    "## 4. KAIST_roboflow \n",
    "\n",
    "from bases.kaist import KAIST\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/kaist_roboflow/annotations\")\n",
    "annotation_file = converted_path / \"kaist_train_annotations_coco.json\"\n",
    "\n",
    "D = KAIST(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"kaist_roboflow\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. KAIST pedestrian dataset**\n",
    "\n",
    "```python\n",
    "\n",
    "## 5. KAIST pedestrian dataset\n",
    "\n",
    "from bases.kaist_pedestrian import KAIST\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/kaist_pedestrian/converted_annotations\")\n",
    "annotation_file = converted_path / \"kaist_converted_to_coco_format.json\"\n",
    "\n",
    "D = KAIST(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"kaist_pedestrian\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. VHR10**\n",
    "\n",
    "```python\n",
    "## 6. VHR10\n",
    "\n",
    "from bases.vhr import VHR10\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/vhr_10/annotations\")\n",
    "annotation_file = converted_path / \"vhr_annotations.json\"\n",
    "\n",
    "D = VHR10(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"vhr_10\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **7. DOTA v2.0 dataset**\n",
    "\n",
    "\n",
    "```python\n",
    "## 7. DOTA train dataset \n",
    "\n",
    "from bases.dota import DOTA\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/dota/converted_annotations\")\n",
    "annotation_file = converted_path / \"dotav2_converted_to_coco.json\"\n",
    "\n",
    "# if annotation_file does not exist, convert the dataset\n",
    "if not annotation_file.exists():\n",
    "\n",
    "    try:\n",
    "        #TODO this could be improved \n",
    "        # The script could take arguments \n",
    "        print(\"[INFO] Converting dota dataset to COCO format...\")\n",
    "        os.system(\"python ./scripts/convert_dota_to_coco_format.py\")\n",
    "        print(\"[INFO] Finished converting dataset to COCO format.\")\n",
    "    except:\n",
    "        print(\"[ERROR] Could not convert dataset to COCO format.\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "D = DOTA(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"DOTA\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "                            \n",
    "                            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **8. VEDAI dataset**\n",
    "\n",
    "\n",
    "```python\n",
    "## 8. Vedai dataset \n",
    "\n",
    "from bases.vedai import VEDAI\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/vedai/converted_annotations\")\n",
    "annotation_file = converted_path / \"vedai_converted_to_coco_format.json\"\n",
    "\n",
    "# if annotation_file does not exist, convert the dataset\n",
    "if not annotation_file.exists():\n",
    "\n",
    "    try:\n",
    "        #TODO this could be improved \n",
    "        # The script could take arguments \n",
    "        print(\"[INFO] Converting vedai dataset to COCO format...\")\n",
    "        os.system(\"python ./scripts/convert_vedai_to_coco_format.py\")\n",
    "        print(\"[INFO] Finished converting dataset to COCO format.\")\n",
    "    except:\n",
    "        print(\"[ERROR] Could not convert dataset to COCO format.\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "D = VEDAI(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"vedai\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "                            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                          \n",
    "\n",
    "## **9. KITTI dataset**\n",
    "\n",
    "\n",
    "```python\n",
    "## 9. KITTI dataset\n",
    "\n",
    "from bases.kittidet import KITTI\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "converted_path = Path(\"./data/kitti/converted_annotations\")\n",
    "annotation_file = converted_path / \"kitti_converted_to_coco_format.json\"\n",
    "\n",
    "# if annotation_file does not exist, convert the dataset\n",
    "if not annotation_file.exists():\n",
    "\n",
    "    try:\n",
    "        #TODO this could be improved \n",
    "        # The script could take arguments \n",
    "        print(\"[INFO] Converting kitti dataset to COCO format...\")\n",
    "        os.system(\"python ./scripts/convert_kitti_to_coco.py\")\n",
    "        print(\"[INFO] Finished converting dataset to COCO format.\")\n",
    "    except:\n",
    "        print(\"[ERROR] Could not convert dataset to COCO format.\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "D = KITTI(annotation_file=str(annotation_file))\n",
    "\n",
    "# generate and load stats\n",
    "D.generate_dataset_statistics()\n",
    "\n",
    "# save the stats\n",
    "D.save_dataset_statistics(save_path = \"./summaries\",\n",
    "                            dataset_name = f\"kitti\",\n",
    "                            file_name = f\"{annotation_file.stem}_stats.json\"\n",
    "                            )\n",
    "                            \n",
    "```  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsetStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
